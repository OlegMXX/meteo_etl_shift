# Meteo ETL

## Описание
**Meteo ETL** — это приложение для автоматизации сбора метеоданных с https://open-meteo.com/, их обработки и записи в базу данных или выгрузки в CSV-файл.
- **Язык разработки**: Python
- **База данных**: PostgreSQL 13
- **Прочие библиотеки**:
  - **asyncpg** — асинхронная работа с PostgreSQL.
  - **requests** — HTTP-запросы.
  - **passlib** — библиотека для работы с хэшированием паролей, включая поддержку bcrypt.
  - **pre-commit** — автоматическое выполнение линтеров и других проверок перед коммитами.
  - **python-dotenv** — работа с переменными окружения из файла `.env`.

## Запуск проекта

1. Создать виртуальное окружение

для Windows:

```
python -m venv venv
```
для Linux:

```
python3 -m venv venv
```

2. Активировать окружение

для Windows:

```
venv/Scripts/activate.ps1
```

для Linux:

```
source venv/bin/activate
```

3. Установить зависимости

```
pip install -r requirements.txt
```

4. В корневой директории проекта создать файл
.env для переменных окружение
файл заполнить следующими данными или использовать свои.

```
#=====POSTGRESS_SETTINGS=====#

POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_USER=admin
POSTGRES_PASSWORD=admin
POSTGRES_DB=db


````


5. Запуск инстанса БД

```
docker-compose up --build
```

6. Запустить файл main.py

```
python src/main.py
````

7. Следуйте инструкциям приложения.

Пример ввода:
```
2025-05-01
2025-05-10
y
y
````

## Заметки для проверяющего:
- Выбор технологий. Я решил минимизировать использование любых фреймворков и библиотек, чтобы проект был максимально Pure Python. Только минимально-необходимое.
- Проектирование. У меня есть опыт работы с веб-приложениями и мне очень нравится предметно-ориентированное проектирование (DDD), поэтому приложение я сделал таким:
          модели данных (models) полностью изолированы от методов обработки(services),
          все вычислительные функции так же изолированы (utils),
          ядро приложения (core) изолировано от интерфейса (main).
- Дубликаты.Из всех полей только время восхода и заката - уникальные, поэтому дубликаты я ищу по ним. Это строчные значения, что не очень сказывается на скорости, я бы подумал о составном суррогатном ключе в будущем.
- Синхронность и асинхронность. Мы делаем один запрос на API и пока не придет результат, нам нечего делать. Так же обработка запроса - CPU-bound, и пока не получим готовые объекты, можно оставаться в синхронном потоке. Вот отправка данных в Postgres объектов по одному (это легкий способ обрабатывать дубликаты) - I/O-bound, это уже позволяет использовать асинхронность.
- ООП везде. Отдельно про мои гигантские объекты Погоды на день: я их облегчил по весу, использовав __slots__. Люблю ООП. Можно было обойтись словарями или датаклассами, но это скучно.
- Когда приложение было уже почти готово и я смог вводить даты сам, я обнаружил огромные списки из Null в респонзах по датам до 2025-05-01. Обрабатывать это у меня уже не было времени.
